\chapter{3D Model Building}
This chapter describes how to build a generative textured 3D face model from an example set of 3D face scans. A morphable model is derived from the set of scans by transforming their shape and texture into a vector space representation. The term generative implies that - as the face space is spanned by the set of examples - new faces can be generated by calculating linear combinations of these examples. 

\section{3D Morphable Model}
The 3D Morphable Model (3DMM) published by Blanz and Vetter in 1999 (bib) is a multidimensional function for modelling textured faces derived from a large set of 3D face scans. 
A vector space of face shapes can be constructed from the available data set where each face is represented by a shape-vector $S \in \mathbb{R}^{3n}$ that consists of a component-wise listing of its $n$ vertices. The texture-vector then $T \in
\mathbb{T}^{3n}$ contains the corresponding RGB values in similar fassion.
New shapes and textures can now be constructed with a linear combination of the set of $m$ available faces governed by shape and texture coefficients $\vec\alpha, \vec\beta \in \mathbb{R}^{m}$.
\begin{equation}
\label{eq:MM}
\mathcal{S}_{new}=\sum_{i=1}^{m}\alpha_{i}S_{i}, \quad \mathcal{T}_{new}=\sum_{i=1}^{m}\beta_{i}T_{i}
\end{equation}
However, the goal of such a 3D face model is not just to construct arbitrary faces with linear combinations of the set of examples, but to derive plausible faces from them. This is achieved by estimating two multivariate normal distributions for the coefficients in $\vec\alpha$ and $\vec\beta$.
These multivariate normal distributions are constructed from the average face shapes $\overline{S} \in \mathbb{R}^{3N}$ and textures $\overline{T} \in \mathbb{R}^{3N}$ of the datasets and the covariance matrices $K_{S}$ and $K_{T}$, which are defined over the residuals of each example and with both the shape $R_{S}=S-\overline{S}$ and texture $R_{T}=T-\overline{T}$ averages. The covariance matrices are then used to perform Principal Component Analysis (PCA)
which defines a basis transformation to an orthogonal coordinate systems. The axes are defined by the eigenvectors of the respective covariance matrix.
\begin{equation}
\label{eq:MM}
\mathcal{S}(\vec\alpha)=\overline{S}+M_{S}\vec\alpha, \quad \mathcal{T}(\vec\beta)=\overline{T}+M_{T}\vec\beta
\end{equation}
In \eqref{eq:MM} the $N=m$ principal eigenvectors of $K_{S}$ and $K_{T}$ respectively are assembled column-wise in $M_{S}$ and $M_{T}$ and scaled in a way such that the prior distribution over the face shape and texture parameters is given by a multivariate normal distribution with unit covariance (Amberg).
\begin{equation}
    p(\vec\alpha, \vec\beta) = \mathcal{N}(\vec\alpha\vert|\vect{0}, \mathbb{I})\mathcal{N}(\vec\beta\vert|\vect{0}, \mathbb{I})
\end{equation}
Calculating the likelihood for a set of coefficients is straightforward and therefore it is now possible to find out how likely a face is given the model. 
\begin{comment}
By observing the likelihood of the coefficients it is now possible to find out how likely/admissible/plausible the appearance of a corresponding face is.
\viscomment{likelihood of the faces p(faces | unknown parameter values) OR what are the most likely parameters given the available set of faces}
\end{comment}

\section{Achieving Correspondence through Registration}
In order for a 3D Morphable Model to generate plausible faces we have to make sure that all faces share the same representation, so that only the same parts of the respective faces are combined with one another. For example a nose is combined with another nose and not with a mouth. For this reason, the meshs first have to be brought into correspondence. In fact, we need dense correspondence between all mesh points. This is the case when vertices at the same semantical position in
different meshs have the same vertex number, i.e the left corner of the left eye. The process of calculating a dense point-to-point correspondence between two meshs is called registration.  
\begin{comment}
meaning that all faces share the same mesh triangulation, respectively the vertices at the same semantical position, i.e. the corner of the eye, have a similar vertex number. Correspondence is achieved/accomplished through the process of registration.
\textit{Now in order to obtain a 3D representations of the face we need to transform a template face so that it fits a particular 3D face scan. To find the transformation, however, we first have to find feature points in both 3D representations which correspond to the same semantical structure. Previous work has shown that point landmarks are not sufficient to preserve the level of detail which is imminent in the regions of the eyes, ears and lips and that the computed
transformations are not able to preserve these regions. For this reason, additional line features have been introduced. In order to relate these}
\end{comment} 
The training data used for learning a 3D Morphable Models consists solely of registered examples of the 3D shape and texture of faces.

\paragraph{Registration Algorithms}
When performing registration, we start with a template shape that is a prototype of the semantic parametrization. In order to compute the parametrization for another shape we deform the template to match this shape. The shape being matched is referred to as the target. Both are considered as matched if the semantic face regions are mapped onto each other as closely as possible by satisfying a specified similarity measure. If dense correspondence is achieved, the target shape can be replaced with the deformed template, which will further be used in the process of building a model.\\
Today's registration algorithms use prior information in the form of manually clicked feature points at prominent points of the face, so called landmarks. These are important for the alignment of template and target as well as achieving an accurate match. \begin{comment}on all of the face meshs for the purpose of computing an accurate deformation.\end{comment}Correspondence in-between these points is defined through smooth deformations of the template mesh which match the surface and feature points of the target. 

\section{Available Data}
For testing the registration algorithm we have a large set of face scans given - male as well as female - all of them recorded at the University of Basel by an active stereo vision system using structured light. The scanner records four 3D surfaces, called shells, and further records three high resolution color images for every face. 
\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{./resources/figures/scanner.pdf}
\caption{schema of the structured light 3D scanning system employed to record the facial scans. It consists of two projectors that project triangle gradient patterns on to a face from opposing angles, three black-and-white cameras used for the triangulation and three digital cameras which record the facial skin.}
\label{fig:scanner}
\end{figure}
The 3D shells are obtained through triangulation.
Each of the four black-and-white cameras \ref{fig:scanner} records the triangle gradient patterns - stripe patterns - emitted from the two projectors. The patterns allow for the extraction of depth information by the four neighbouring projector-camera-pairs using triangulation.  
The eyes and hair can not be captured due to their reflection properties. Therefore the shells only cover the front and the side of the head and have holes in the eyes and instead of parts of the ears. 
The face textures are obtained from the color images.
\begin{figure}[h!]
    \subfloat[3D shells]{\includegraphics[width=.7\textwidth]{./resources/figures/shells.eps}}
    \subfloat[merged shells]{\includegraphics[width=.3\textwidth]{./resources/figures/scan.eps}}
\caption{\ldots}
\label{fig:scan}
\end{figure}
To obtain a whole mesh the 3D shells first have to be cleaned and then merged.
The scans are further manually annotated with a set of so called landmarks \ref{fig:landmarks}. 
\begin{wrapfigure}{r}{.4\textwidth}
    \centering
    \includegraphics[width=.3\textwidth]{./resources/figures/schema_marked.eps}
    \label{fig:landmarks}
\end{wrapfigure}
Furthermore, they are used to create 2D parametric curves that describe key regions of the face, i.e. the eyes. The line features will be fully introduced together with the registration pipeline. In the next chapter we will elaborate on the approach of using Gaussian Processes to solving the problem 3D face registration and then describe how to incorporate the annotations.
\begin{comment}
From these scans we want to create fully textured 3D faces, which can be used to build a new face model.
\end{comment}
